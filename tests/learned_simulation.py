"""
í•™ìŠµëœ ëª¨ë¸ë¡œ GridWorldë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ì½”ë“œ
í›ˆë ¨ëœ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
"""
import gymnasium as gym
import gymnasium_env
from stable_baselines3 import A2C, PPO, DQN
import numpy as np
import time
import os


def load_and_simulate(model_path, model_type='A2C', episodes=5, render_mode='human'):
    """
    í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ GridWorld ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

    Args:
        model_path: í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        model_type: ëª¨ë¸ íƒ€ì… ('A2C', 'PPO', 'DQN')
        episodes: ì‹¤í–‰í•  ì—í”¼ì†Œë“œ ìˆ˜
        render_mode: ë Œë”ë§ ëª¨ë“œ ('human', 'rgb_array')
    """
    print(f"=== í•™ìŠµëœ {model_type} ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜ ===")

    # í™˜ê²½ ìƒì„±
    env = gym.make('gymnasium_env/GridWorld-v0', render_mode=render_mode, size=5)

    # ëª¨ë¸ ë¡œë“œ
    try:
        if model_type == 'A2C':
            model = A2C.load(model_path)
        elif model_type == 'PPO':
            model = PPO.load(model_path)
        elif model_type == 'DQN':
            model = DQN.load(model_path)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}")

        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # ì‹œë®¬ë ˆì´ì…˜ í†µê³„
    episode_rewards = []
    episode_steps = []
    success_count = 0

    for episode in range(episodes):
        print(f"\n--- ì—í”¼ì†Œë“œ {episode + 1}/{episodes} ---")

        obs, info = env.reset()
        episode_reward = 0
        step_count = 0

        print(f"ì‹œì‘ ìƒíƒœ:")
        print(f"  ì—ì´ì „íŠ¸: {obs['agent']}")
        print(f"  ëª©í‘œ: {obs['target']}")
        print(f"  ì´ˆê¸° ê±°ë¦¬: {info['distance']:.1f}")

        # í™˜ê²½ ë Œë”ë§
        if render_mode == 'human':
            env.render()
            time.sleep(1)  # ì´ˆê¸° ìƒíƒœ í™•ì¸ ì‹œê°„

        while True:
            # í•™ìŠµëœ ì •ì±…ìœ¼ë¡œ í–‰ë™ ì„ íƒ
            action, _ = model.predict(obs, deterministic=True)
            action_names = ['ì˜¤ë¥¸ìª½', 'ìœ„', 'ì™¼ìª½', 'ì•„ë˜']

            print(f"ìŠ¤í… {step_count + 1}: ì •ì±… ì„ íƒ -> {action_names[action]}")

            # í–‰ë™ ì‹¤í–‰
            obs, reward, terminated, truncated, info = env.step(action)
            episode_reward += reward
            step_count += 1

            print(f"  ê²°ê³¼: ìœ„ì¹˜ {obs['agent']}, ë³´ìƒ {reward:.3f}, ê±°ë¦¬ {info['distance']:.1f}")

            # ë Œë”ë§ ë° ë”œë ˆì´
            if render_mode == 'human':
                env.render()
                time.sleep(0.8)  # ì‚¬ëŒì´ ë³´ê¸° ì¢‹ì€ ì†ë„

            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if terminated:
                print(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±! {step_count}ìŠ¤í…ìœ¼ë¡œ ì„±ê³µ")
                success_count += 1
                break
            elif truncated:
                print(f"â±ï¸ ì‹œê°„ ì´ˆê³¼ ({step_count}ìŠ¤í…)")
                break

        episode_rewards.append(episode_reward)
        episode_steps.append(step_count)

        print(f"ì—í”¼ì†Œë“œ ê²°ê³¼: ë³´ìƒ {episode_reward:.3f}, ìŠ¤í… {step_count}")

        # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì „ ëŒ€ê¸°
        if render_mode == 'human' and episode < episodes - 1:
            time.sleep(2)

    env.close()

    # ìµœì¢… í†µê³„ ì¶œë ¥
    print(f"\n=== {model_type} ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ ===")
    print(f"ì´ ì—í”¼ì†Œë“œ: {episodes}")
    print(f"ì„±ê³µë¥ : {success_count / episodes * 100:.1f}% ({success_count}/{episodes})")
    print(f"í‰ê·  ë³´ìƒ: {np.mean(episode_rewards):.3f} Â± {np.std(episode_rewards):.3f}")
    print(f"í‰ê·  ìŠ¤í…: {np.mean(episode_steps):.1f} Â± {np.std(episode_steps):.1f}")
    if success_count > 0:
        success_steps = [steps for i, steps in enumerate(episode_steps)
                         if episode_rewards[i] > 0]
        print(f"ì„±ê³µ ì‹œ í‰ê·  ìŠ¤í…: {np.mean(success_steps):.1f}")
    print(f"ìµœê³  ì„±ëŠ¥: {np.max(episode_rewards):.3f} ë³´ìƒ, {np.min(episode_steps)} ìŠ¤í…")


def compare_models(model_configs, episodes=3):
    """
    ì—¬ëŸ¬ í•™ìŠµëœ ëª¨ë¸ì„ ë¹„êµí•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.

    Args:
        model_configs: [(model_path, model_type, name), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        episodes: ê° ëª¨ë¸ë‹¹ ì‹¤í–‰í•  ì—í”¼ì†Œë“œ ìˆ˜
    """
    print("=== ë‹¤ì¤‘ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ===")

    results = {}

    for model_path, model_type, name in model_configs:
        if not os.path.exists(model_path):
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {model_path}")
            continue

        print(f"\nğŸ¤– {name} ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")

        # í™˜ê²½ ìƒì„± (ë Œë”ë§ ì—†ì´ ë¹ ë¥´ê²Œ)
        env = gym.make('gymnasium_env/GridWorld-v0', size=5)

        try:
            # ëª¨ë¸ ë¡œë“œ
            if model_type == 'A2C':
                model = A2C.load(model_path)
            elif model_type == 'PPO':
                model = PPO.load(model_path)
            elif model_type == 'DQN':
                model = DQN.load(model_path)

            episode_rewards = []
            episode_steps = []
            success_count = 0

            # ë¹ ë¥¸ ì‹œë®¬ë ˆì´ì…˜ (ë Œë”ë§ ì—†ì´)
            for episode in range(episodes):
                obs, info = env.reset()
                episode_reward = 0
                step_count = 0

                while True:
                    action, _ = model.predict(obs, deterministic=True)
                    obs, reward, terminated, truncated, info = env.step(action)
                    episode_reward += reward
                    step_count += 1

                    if terminated:
                        success_count += 1
                        break
                    elif truncated:
                        break

                episode_rewards.append(episode_reward)
                episode_steps.append(step_count)

            env.close()

            # ê²°ê³¼ ì €ì¥
            results[name] = {
                'success_rate': success_count / episodes * 100,
                'avg_reward': np.mean(episode_rewards),
                'avg_steps': np.mean(episode_steps),
                'std_reward': np.std(episode_rewards),
                'std_steps': np.std(episode_steps)
            }

            print(f"âœ… {name}: ì„±ê³µë¥  {results[name]['success_rate']:.1f}%, "
                  f"í‰ê·  ë³´ìƒ {results[name]['avg_reward']:.3f}")

        except Exception as e:
            print(f"âŒ {name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    # ë¹„êµ ê²°ê³¼ ì¶œë ¥
    if results:
        print(f"\n{'=' * 50}")
        print("ğŸ† ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print(f"{'=' * 50}")
        print(f"{'ëª¨ë¸ëª…':<15} {'ì„±ê³µë¥ ':<10} {'í‰ê· ë³´ìƒ':<12} {'í‰ê· ìŠ¤í…':<10}")
        print("-" * 50)

        for name, stats in sorted(results.items(),
                                  key=lambda x: x[1]['success_rate'],
                                  reverse=True):
            print(f"{name:<15} {stats['success_rate']:>7.1f}%  "
                  f"{stats['avg_reward']:>9.3f}    {stats['avg_steps']:>7.1f}")


def interactive_model_demo():
    """ëŒ€í™”í˜• ëª¨ë¸ ë°ëª¨ - ì‚¬ìš©ìê°€ ëª¨ë¸ì„ ì„ íƒí•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜"""
    print("=== í•™ìŠµëœ ëª¨ë¸ ë°ëª¨ ì‹œìŠ¤í…œ ===")

    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ê²€ìƒ‰
    model_dir = "models"  # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
    if not os.path.exists(model_dir):
        print(f"âš ï¸ ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {model_dir}")
        print("ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        return

    available_models = []
    for filename in os.listdir(model_dir):
        if filename.endswith('.zip'):
            available_models.append(filename)

    if not available_models:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
    for i, model in enumerate(available_models):
        print(f"{i + 1}. {model}")

    try:
        choice = int(input(f"ëª¨ë¸ ì„ íƒ (1-{len(available_models)}): ")) - 1
        if 0 <= choice < len(available_models):
            selected_model = available_models[choice]
            model_path = os.path.join(model_dir, selected_model)

            # ëª¨ë¸ íƒ€ì… ì¶”ì •
            if 'a2c' in selected_model.lower():
                model_type = 'A2C'
            elif 'ppo' in selected_model.lower():
                model_type = 'PPO'
            elif 'dqn' in selected_model.lower():
                model_type = 'DQN'
            else:
                model_type = input("ëª¨ë¸ íƒ€ì…ì„ ì…ë ¥í•˜ì„¸ìš” (A2C/PPO/DQN): ").upper()

            episodes = int(input("ì‹¤í–‰í•  ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸ 3): ") or 3)

            load_and_simulate(model_path, model_type, episodes, 'human')
        else:
            print("ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    except (ValueError, KeyboardInterrupt):
        print("ì…ë ¥ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    print("GridWorld í•™ìŠµëœ ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜")
    print("1. íŠ¹ì • ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜")
    print("2. ë‹¤ì¤‘ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    print("3. ëŒ€í™”í˜• ëª¨ë¸ ë°ëª¨")

    try:
        choice = input("ì„ íƒ (1-3): ")

        if choice == "1":
            model_path = input("ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: ")
            model_type = input("ëª¨ë¸ íƒ€ì… (A2C/PPO/DQN): ").upper()
            episodes = int(input("ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸ 5): ") or 5)
            load_and_simulate(model_path, model_type, episodes)

        elif choice == "2":
            # ì˜ˆì‹œ ëª¨ë¸ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)
            configs = [
                ("models/a2c_gridworld.zip", "A2C", "A2C ê¸°ë³¸"),
                ("models/ppo_gridworld.zip", "PPO", "PPO ê¸°ë³¸"),
                ("models/dqn_gridworld.zip", "DQN", "DQN ê¸°ë³¸"),
            ]
            compare_models(configs, episodes=5)

        elif choice == "3":
            interactive_model_demo()

        else:
            print("ì˜¬ë°”ë¥¸ ì„ íƒì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
